# =============================================================================
# –õ–ê–ë–û–†–ê–¢–û–†–ù–ê–Ø –†–ê–ë–û–¢–ê 3
# –ó–∞–¥–∞—á–∞ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏: –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–æ–≤ –±–∞–Ω–∫–∞
# =============================================================================

# –í–°–ï –ò–ú–ü–û–†–¢–´
import platform
import warnings

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
import sklearn
from IPython.display import display
from scipy.cluster.hierarchy import dendrogram, linkage
from sklearn.cluster import DBSCAN, AgglomerativeClustering, KMeans
from sklearn.decomposition import PCA
from sklearn.metrics import (
    adjusted_rand_score,
    calinski_harabasz_score,
    davies_bouldin_score,
    silhouette_samples,
    silhouette_score,
)
from sklearn.preprocessing import LabelEncoder, StandardScaler

warnings.filterwarnings("ignore")

# –≠–¢–ê–ü 1: –ü–û–°–¢–ê–ù–û–í–ö–ê –ó–ê–î–ê–ß–ò –ò –î–ê–ù–ù–´–ï

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
PALETTE = "Set2"
sns.set(style="whitegrid")
plt.rcParams["figure.figsize"] = (12, 6)
plt.rcParams["font.size"] = 12

RANDOM_STATE = 42

print("=" * 70)
print("–õ–ê–ë–û–†–ê–¢–û–†–ù–ê–Ø –†–ê–ë–û–¢–ê 3: –ö–õ–ê–°–¢–ï–†–ò–ó–ê–¶–ò–Ø –ö–õ–ò–ï–ù–¢–û–í –ë–ê–ù–ö–ê")
print("=" * 70)

print("\n--- –≠–¢–ê–ü 1: –ü–û–°–¢–ê–ù–û–í–ö–ê –ó–ê–î–ê–ß–ò –ò –î–ê–ù–ù–´–ï ---\n")

print("–û–ü–ò–°–ê–ù–ò–ï –ó–ê–î–ê–ß–ò:")
print("-" * 50)
print("""
–¢–∏–ø –∑–∞–¥–∞—á–∏: –ö–õ–ê–°–¢–ï–†–ò–ó–ê–¶–ò–Ø (–æ–±—É—á–µ–Ω–∏–µ –±–µ–∑ —É—á–∏—Ç–µ–ª—è)

–¶–µ–ª—å: –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–æ–≤ –±–∞–Ω–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫
–¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–æ–≤—ã—Ö –∫–∞–º–ø–∞–Ω–∏–π.

–ë–∏–∑–Ω–µ—Å-–∑–∞–¥–∞—á–∞:
- –í—ã—è–≤–∏—Ç—å –≥—Ä—É–ø–ø—ã –∫–ª–∏–µ–Ω—Ç–æ–≤ —Å–æ —Å—Ö–æ–∂–∏–º–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º–∏
- –ü–æ–Ω—è—Ç—å, –∫–∞–∫–∏–µ —Å–µ–≥–º–µ–Ω—Ç—ã –Ω–∞–∏–±–æ–ª–µ–µ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω—ã –¥–ª—è –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–∞
- –ü–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞
""")

print("=" * 60)
print("–û–ë–û–°–ù–û–í–ê–ù–ò–ï –í–´–ë–û–†–ê –ö–õ–ê–°–¢–ï–†–ò–ó–ê–¶–ò–ò (–∞ –Ω–µ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏/—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π)")
print("=" * 60)
print("""
–í –õ–†3 –ø—Ä–µ–¥–ª–∞–≥–∞–ª–æ—Å—å –≤—ã–±—Ä–∞—Ç—å –æ–¥–Ω—É –∏–∑ —Ç—Ä—ë—Ö –∑–∞–¥–∞—á:
  1) –†–µ–≥—Ä–µ—Å—Å–∏—è
  2) –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è
  3) –†–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞

–ú–´ –í–´–ë–†–ê–õ–ò –ö–õ–ê–°–¢–ï–†–ò–ó–ê–¶–ò–Æ –ø–æ —Å–ª–µ–¥—É—é—â–∏–º –ø—Ä–∏—á–∏–Ω–∞–º:

–ü–û–ß–ï–ú–£ –ù–ï –†–ï–ì–†–ï–°–°–ò–Ø?
  ‚Ä¢ –í –Ω–∞—à–µ–º –¥–∞—Ç–∞—Å–µ—Ç–µ –ù–ï–¢ –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–π —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –¥–ª—è
    –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è (y - –±–∏–Ω–∞—Ä–Ω–∞—è: yes/no)
  ‚Ä¢ –ú–æ–∂–Ω–æ –±—ã–ª–æ –±—ã –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å duration (–¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∑–≤–æ–Ω–∫–∞),
    –Ω–æ —ç—Ç–æ –Ω–µ –∏–º–µ–µ—Ç –±–∏–∑–Ω–µ—Å-—Å–º—ã—Å–ª–∞ - –æ–Ω–∞ –∏–∑–≤–µ—Å—Ç–Ω–∞ —Ç–æ–ª—å–∫–æ –ü–û–°–õ–ï –∑–≤–æ–Ω–∫–∞
  ‚Ä¢ –≠–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –æ–¥–∏–Ω–∞–∫–æ–≤—ã –¥–ª—è –≤—Å–µ—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤ –≤ –º–æ–º–µ–Ω—Ç
    –≤—Ä–µ–º–µ–Ω–∏ - –∏—Ö –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å –Ω–µ–ª–æ–≥–∏—á–Ω–æ

–ü–û–ß–ï–ú–£ –ù–ï –†–ï–ö–û–ú–ï–ù–î–ê–¢–ï–õ–¨–ù–ê–Ø –°–ò–°–¢–ï–ú–ê?
  ‚Ä¢ –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å-—Ç–æ–≤–∞—Ä (user-item)
  ‚Ä¢ –ù–µ—Ç —Ä–µ–π—Ç–∏–Ω–≥–æ–≤ –∏–ª–∏ –∏—Å—Ç–æ—Ä–∏–∏ –ø–æ–∫—É–ø–æ–∫
  ‚Ä¢ –î–∞—Ç–∞—Å–µ—Ç –æ–ø–∏—Å—ã–≤–∞–µ—Ç —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∫–ª–∏–µ–Ω—Ç–æ–≤, –∞ –Ω–µ –∏—Ö –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è
  ‚Ä¢ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è collaborative filtering

–ü–û–ß–ï–ú–£ –ö–õ–ê–°–¢–ï–†–ò–ó–ê–¶–ò–Ø - –õ–£–ß–®–ò–ô –í–´–ë–û–†?
  ‚úì –î–∞—Ç–∞—Å–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∫–ª–∏–µ–Ω—Ç–æ–≤
    (–¥–µ–º–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ, —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ, –ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏–µ)
  ‚úì –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –ø–æ–∑–≤–æ–ª–∏—Ç –Ω–∞–π—Ç–∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –≥—Ä—É–ø–ø—ã –∫–ª–∏–µ–Ω—Ç–æ–≤
  ‚úì –ù–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (–æ–±—É—á–µ–Ω–∏–µ –±–µ–∑ —É—á–∏—Ç–µ–ª—è)
  ‚úì –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–º–µ—é—Ç –ø—Ä—è–º—É—é –±–∏–∑–Ω–µ—Å-—Ü–µ–Ω–Ω–æ—Å—Ç—å:
    - –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –¥–ª—è —Ç–∞—Ä–≥–µ—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–∞
    - –ü–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –¥–ª—è –∫–∞–∂–¥–æ–π –≥—Ä—É–ø–ø—ã
    - –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Ä–µ—Å—É—Ä—Å–æ–≤ –Ω–∞ –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–æ–≤—ã–µ –∫–∞–º–ø–∞–Ω–∏–∏
  ‚úì –õ–æ–≥–∏—á–µ—Å–∫–∏ –¥–æ–ø–æ–ª–Ω—è–µ—Ç –õ–†1 (EDA) –∏ –õ–†2 (–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è)
""")

# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
print("\n–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
try:
    url = "https://drive.google.com/uc?id=1dvVgFSH22J7okTKYD8sHzJvJJ9MRZzkN&export=download"
    df = pd.read_csv(url, delimiter=";")
    print("‚úì –§–∞–π–ª —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω")
except Exception as e:
    print(f"‚úó –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞: {e}")
    exit(1)

# –°–ª–æ–≤–∞—Ä—å –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ –Ω–∞–∑–≤–∞–Ω–∏–π —Å—Ç–æ–ª–±—Ü–æ–≤
COLUMN_TRANSLATOR = {
    "age": "–í–æ–∑—Ä–∞—Å—Ç",
    "job": "–ü—Ä–æ—Ñ–µ—Å—Å–∏—è",
    "marital": "–°–µ–º–µ–π–Ω–æ–µ –ø–æ–ª–æ–∂–µ–Ω–∏–µ",
    "education": "–û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ",
    "default": "–ö—Ä–µ–¥–∏—Ç–Ω—ã–π –¥–µ—Ñ–æ–ª—Ç",
    "housing": "–ò–ø–æ—Ç–µ–∫–∞",
    "loan": "–ü–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—å—Å–∫–∏–π –∫—Ä–µ–¥–∏—Ç",
    "contact": "–¢–∏–ø –∫–æ–Ω—Ç–∞–∫—Ç–∞",
    "month": "–ú–µ—Å—è—Ü",
    "day_of_week": "–î–µ–Ω—å –Ω–µ–¥–µ–ª–∏",
    "duration": "–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∑–≤–æ–Ω–∫–∞ (—Å–µ–∫)",
    "campaign": "–ö–æ–ª-–≤–æ –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤ –≤ –∫–∞–º–ø–∞–Ω–∏–∏",
    "pdays": "–î–Ω–µ–π —Å –ø—Ä–æ—à–ª–æ–≥–æ –∫–æ–Ω—Ç–∞–∫—Ç–∞",
    "previous": "–ö–æ–ª-–≤–æ –ø—Ä–æ—à–ª—ã—Ö –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤",
    "poutcome": "–†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–æ—à–ª–æ–π –∫–∞–º–ø–∞–Ω–∏–∏",
    "emp.var.rate": "–ò–∑–º. —É—Ä–æ–≤–Ω—è –∑–∞–Ω—è—Ç–æ—Å—Ç–∏",
    "cons.price.idx": "–ò–Ω–¥–µ–∫—Å –ø–æ—Ç—Ä–µ–±. —Ü–µ–Ω",
    "cons.conf.idx": "–ò–Ω–¥–µ–∫—Å –ø–æ—Ç—Ä–µ–±. –¥–æ–≤–µ—Ä–∏—è",
    "euribor3m": "–°—Ç–∞–≤–∫–∞ Euribor 3M",
    "nr.employed": "–ß–∏—Å–ª–æ –∑–∞–Ω—è—Ç—ã—Ö",
    "y": "–°–æ–≥–ª–∞—Å–∏–µ –Ω–∞ –≤–∫–ª–∞–¥",
}

print("\n–û–ü–ò–°–ê–ù–ò–ï –î–ê–¢–ê–°–ï–¢–ê:")
print("-" * 50)
print(f"–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: {df.shape[0]} —Å—Ç—Ä–æ–∫ √ó {df.shape[1]} —Å—Ç–æ–ª–±—Ü–æ–≤")

print("\n–ü–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫ –¥–∞—Ç–∞—Å–µ—Ç–∞:")
display(df.head())

print("\n–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ç–∏–ø–∞—Ö –¥–∞–Ω–Ω—ã—Ö:")
df.info()

# –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏
print("\n--- –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ ---")

# –£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
df.drop_duplicates(inplace=True)
print(f"‚úì –î—É–±–ª–∏–∫–∞—Ç—ã —É–¥–∞–ª–µ–Ω—ã. –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: {df.shape}")

# –û–±—Ä–∞–±–æ—Ç–∫–∞ 'unknown' –∑–Ω–∞—á–µ–Ω–∏–π
object_cols = df.select_dtypes(include=["object"]).columns
for col in object_cols:
    if "unknown" in df[col].unique():
        mode_value = df[col].mode()[0]
        if mode_value == "unknown":
            second_mode = df[col].value_counts().index[1]
            df[col] = df[col].replace("unknown", second_mode)
        else:
            df[col] = df[col].replace("unknown", mode_value)
print("‚úì –ó–Ω–∞—á–µ–Ω–∏—è 'unknown' –∑–∞–º–µ–Ω–µ–Ω—ã –Ω–∞ –º–æ–¥—É")

# –î–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∫–ª–∏–µ–Ω—Ç–∞
clustering_features = [
    "age",
    "job",
    "marital",
    "education",
    "default",
    "housing",
    "loan",
    "campaign",
    "pdays",
    "previous",
    "poutcome",
]

df_cluster = df[clustering_features].copy()
print(f"\n‚úì –í—ã–±—Ä–∞–Ω—ã –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏: {len(clustering_features)} —à—Ç.")
print(f"  {clustering_features}")


# –≠–¢–ê–ü 2: –ë–ê–ó–û–í–´–ô –ú–ï–¢–û–î (BASELINE) - K-MEANS

print("\n" + "=" * 70)
print("–≠–¢–ê–ü 2: –ë–ê–ó–û–í–´–ô –ú–ï–¢–û–î (BASELINE) - K-MEANS –ö–õ–ê–°–¢–ï–†–ò–ó–ê–¶–ò–Ø")
print("=" * 70)

# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö: –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
print("\n--- –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö ---")

df_encoded = df_cluster.copy()

# Label Encoding –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
label_encoders = {}
categorical_cols = df_encoded.select_dtypes(include=["object"]).columns

for col in categorical_cols:
    le = LabelEncoder()
    df_encoded[col] = le.fit_transform(df_encoded[col])
    label_encoders[col] = le
    print(f"‚úì {col}: –∑–∞–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–æ {len(le.classes_)} –∫–∞—Ç–µ–≥–æ—Ä–∏–π")

# –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ
scaler = StandardScaler()
X_scaled = scaler.fit_transform(df_encoded)
print("\n‚úì –î–∞–Ω–Ω—ã–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω—ã (StandardScaler)")

# –ú–µ—Ç–æ–¥ –ª–æ–∫—Ç—è –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
print("\n--- –ú–µ—Ç–æ–¥ –ª–æ–∫—Ç—è (Elbow Method) ---")

inertias = []
silhouettes = []
K_range = range(2, 11)

for k in K_range:
    kmeans = KMeans(n_clusters=k, random_state=RANDOM_STATE, n_init=10)
    kmeans.fit(X_scaled)
    inertias.append(kmeans.inertia_)
    silhouettes.append(silhouette_score(X_scaled, kmeans.labels_))
    print(f"k={k}: Inertia={kmeans.inertia_:.2f}, Silhouette={silhouettes[-1]:.4f}")

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –º–µ—Ç–æ–¥–∞ –ª–æ–∫—Ç—è
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

axes[0].plot(K_range, inertias, "bo-", linewidth=2, markersize=8)
axes[0].set_xlabel("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ (k)")
axes[0].set_ylabel("–ò–Ω–µ—Ä—Ü–∏—è (Inertia)")
axes[0].set_title("–ú–µ—Ç–æ–¥ –ª–æ–∫—Ç—è: –ò–Ω–µ—Ä—Ü–∏—è vs –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤")
axes[0].grid(True, alpha=0.3)

axes[1].plot(K_range, silhouettes, "go-", linewidth=2, markersize=8)
axes[1].set_xlabel("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ (k)")
axes[1].set_ylabel("Silhouette Score")
axes[1].set_title("Silhouette Score vs –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤")
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig("elbow_method.png", dpi=150, bbox_inches="tight")
plt.show()

print("\nüìä [–°–ö–†–ò–ù–®–û–¢ 1: –ú–µ—Ç–æ–¥ –ª–æ–∫—Ç—è - elbow_method.png]")

# –í—ã–±–∏—Ä–∞–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ k
optimal_k = 4
print(f"\n‚úì –û–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤: k = {optimal_k}")

# –û–±—É—á–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ KMeans (BASELINE)
print("\n--- –û–±—É—á–µ–Ω–∏–µ KMeans (BASELINE) —Å k={} ---".format(optimal_k))

kmeans_final = KMeans(n_clusters=optimal_k, random_state=RANDOM_STATE, n_init=10)
kmeans_labels = kmeans_final.fit_predict(X_scaled)

df["cluster_kmeans"] = kmeans_labels

# –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è baseline
baseline_silhouette = silhouette_score(X_scaled, kmeans_labels)
baseline_inertia = kmeans_final.inertia_
baseline_davies_bouldin = davies_bouldin_score(X_scaled, kmeans_labels)
baseline_calinski = calinski_harabasz_score(X_scaled, kmeans_labels)

print(f"‚úì KMeans (BASELINE) –æ–±—É—á–µ–Ω")
print(f"\n–ú–µ—Ç—Ä–∏–∫–∏ BASELINE (KMeans):")
print(f"  ‚Ä¢ Silhouette Score: {baseline_silhouette:.4f}")
print(f"  ‚Ä¢ Inertia: {baseline_inertia:.2f}")
print(f"  ‚Ä¢ Davies-Bouldin Index: {baseline_davies_bouldin:.4f}")
print(f"  ‚Ä¢ Calinski-Harabasz Index: {baseline_calinski:.2f}")

print(f"\n–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º:")
print(pd.Series(kmeans_labels).value_counts().sort_index())


# –≠–¢–ê–ü 3: –ü–†–û–î–í–ò–ù–£–¢–´–ï –ú–ï–¢–û–î–´ (DBSCAN –∏ Hierarchical Clustering)

print("\n" + "=" * 70)
print("–≠–¢–ê–ü 3: –ü–†–û–î–í–ò–ù–£–¢–´–ï –ú–ï–¢–û–î–´ (DBSCAN –∏ Hierarchical Clustering)")
print("=" * 70)

print("""
–ü–æ –∑–∞–¥–∞–Ω–∏—é –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å:
  ‚Ä¢ DBSCAN - –ø–ª–æ—Ç–Ω–æ—Å—Ç–Ω–∞—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è
  ‚Ä¢ Hierarchical (–∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∞—è) –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è

–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: AgglomerativeClustering –≤ sklearn - —ç—Ç–æ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è
–∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–æ–π –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ "—Å–Ω–∏–∑—É –≤–≤–µ—Ä—Ö" (agglomerative = hierarchical).
""")

# --- 3.1 DBSCAN ---
print("\n--- 3.1 DBSCAN (Density-Based Spatial Clustering) ---")

# –ü–æ–¥–±–æ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ DBSCAN
print("\n–ü–æ–¥–±–æ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ eps –∏ min_samples...")

best_dbscan_score = -1
best_eps = 0
best_min_samples = 0

for eps in [0.5, 1.0, 1.5, 2.0, 2.5, 3.0]:
    for min_samples in [5, 10, 15, 20]:
        dbscan = DBSCAN(eps=eps, min_samples=min_samples)
        labels = dbscan.fit_predict(X_scaled)
        n_clusters = len(set(labels)) - (1 if -1 in labels else 0)
        n_noise = list(labels).count(-1)
        if n_clusters >= 2 and n_clusters <= 10:
            mask = labels != -1
            if mask.sum() > n_clusters:
                score = silhouette_score(X_scaled[mask], labels[mask])
                if score > best_dbscan_score:
                    best_dbscan_score = score
                    best_eps = eps
                    best_min_samples = min_samples

print(f"‚úì –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: eps={best_eps}, min_samples={best_min_samples}")

# –û–±—É—á–µ–Ω–∏–µ DBSCAN —Å –ª—É—á—à–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
dbscan_final = DBSCAN(eps=best_eps, min_samples=best_min_samples)
dbscan_labels = dbscan_final.fit_predict(X_scaled)

n_clusters_dbscan = len(set(dbscan_labels)) - (1 if -1 in dbscan_labels else 0)
n_noise_dbscan = list(dbscan_labels).count(-1)

df["cluster_dbscan"] = dbscan_labels

# –ú–µ—Ç—Ä–∏–∫–∏ DBSCAN
mask_dbscan = dbscan_labels != -1
if mask_dbscan.sum() > n_clusters_dbscan and n_clusters_dbscan >= 2:
    dbscan_silhouette = silhouette_score(
        X_scaled[mask_dbscan], dbscan_labels[mask_dbscan]
    )
    dbscan_davies_bouldin = davies_bouldin_score(
        X_scaled[mask_dbscan], dbscan_labels[mask_dbscan]
    )
    dbscan_calinski = calinski_harabasz_score(
        X_scaled[mask_dbscan], dbscan_labels[mask_dbscan]
    )
else:
    dbscan_silhouette = np.nan
    dbscan_davies_bouldin = np.nan
    dbscan_calinski = np.nan

print(f"\n–†–µ–∑—É–ª—å—Ç–∞—Ç—ã DBSCAN:")
print(f"  ‚Ä¢ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤: {n_clusters_dbscan}")
print(
    f"  ‚Ä¢ –¢–æ—á–∫–∏-—à—É–º (outliers): {n_noise_dbscan} ({n_noise_dbscan / len(df) * 100:.2f}%)"
)
if not np.isnan(dbscan_silhouette):
    print(f"  ‚Ä¢ Silhouette Score: {dbscan_silhouette:.4f}")
print(f"\n–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º (-1 = —à—É–º):")
print(pd.Series(dbscan_labels).value_counts().sort_index())

# --- 3.2 Hierarchical (–ò–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∞—è) –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è ---
print("\n--- 3.2 Hierarchical (–ò–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∞—è) –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è ---")

# –î–µ–Ω–¥—Ä–æ–≥—Ä–∞–º–º–∞ (–Ω–∞ –ø–æ–¥–≤—ã–±–æ—Ä–∫–µ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏)
print("\n–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –¥–µ–Ω–¥—Ä–æ–≥—Ä–∞–º–º—ã...")

sample_size = 1000
np.random.seed(RANDOM_STATE)
sample_indices = np.random.choice(len(X_scaled), size=sample_size, replace=False)
X_sample = X_scaled[sample_indices]

linkage_matrix = linkage(X_sample, method="ward")

plt.figure(figsize=(14, 6))
dendrogram(
    linkage_matrix,
    truncate_mode="lastp",
    p=30,
    leaf_rotation=90,
    leaf_font_size=10,
    show_contracted=True,
)
plt.title("–î–µ–Ω–¥—Ä–æ–≥—Ä–∞–º–º–∞ –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–æ–π –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ (Ward linkage)")
plt.xlabel("–ò–Ω–¥–µ–∫—Å —Ç–æ—á–∫–∏ / –†–∞–∑–º–µ—Ä –∫–ª–∞—Å—Ç–µ—Ä–∞")
plt.ylabel("–†–∞—Å—Å—Ç–æ—è–Ω–∏–µ")
plt.axhline(y=50, color="r", linestyle="--", label="–ü–æ—Ä–æ–≥ –æ—Ç—Å–µ—á–µ–Ω–∏—è")
plt.legend()
plt.tight_layout()
plt.savefig("dendrogram.png", dpi=150, bbox_inches="tight")
plt.show()

print("\nüìä [–°–ö–†–ò–ù–®–û–¢ 2: –î–µ–Ω–¥—Ä–æ–≥—Ä–∞–º–º–∞ - dendrogram.png]")

# –û–±—É—á–µ–Ω–∏–µ Hierarchical Clustering
print(f"\n–û–±—É—á–µ–Ω–∏–µ Hierarchical Clustering —Å k={optimal_k}...")
hierarchical = AgglomerativeClustering(n_clusters=optimal_k, linkage="ward")
hierarchical_labels = hierarchical.fit_predict(X_scaled)

df["cluster_hierarchical"] = hierarchical_labels

# –ú–µ—Ç—Ä–∏–∫–∏ Hierarchical
hierarchical_silhouette = silhouette_score(X_scaled, hierarchical_labels)
hierarchical_davies_bouldin = davies_bouldin_score(X_scaled, hierarchical_labels)
hierarchical_calinski = calinski_harabasz_score(X_scaled, hierarchical_labels)

print(f"‚úì Hierarchical Clustering –æ–±—É—á–µ–Ω")
print(f"\n–ú–µ—Ç—Ä–∏–∫–∏ Hierarchical Clustering:")
print(f"  ‚Ä¢ Silhouette Score: {hierarchical_silhouette:.4f}")
print(f"  ‚Ä¢ Davies-Bouldin Index: {hierarchical_davies_bouldin:.4f}")
print(f"  ‚Ä¢ Calinski-Harabasz Index: {hierarchical_calinski:.2f}")
print(f"\n–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º:")
print(pd.Series(hierarchical_labels).value_counts().sort_index())


# --- 3.3 –°–†–ê–í–ù–ï–ù–ò–ï –° BASELINE –ò –í–´–ë–û–† –ü–û–ë–ï–î–ò–¢–ï–õ–Ø ---
print("\n" + "=" * 60)
print("–°–†–ê–í–ù–ï–ù–ò–ï –ü–†–û–î–í–ò–ù–£–¢–´–• –ú–ï–¢–û–î–û–í –° BASELINE –ò –í–´–ë–û–† –ü–û–ë–ï–î–ò–¢–ï–õ–Ø")
print("=" * 60)

comparison_table = pd.DataFrame(
    {
        "–ú–µ—Ç–æ–¥": ["KMeans (BASELINE)", "DBSCAN", "Hierarchical"],
        "–ö–ª–∞—Å—Ç–µ—Ä–æ–≤": [optimal_k, n_clusters_dbscan, optimal_k],
        "Silhouette": [baseline_silhouette, dbscan_silhouette, hierarchical_silhouette],
        "Davies-Bouldin": [
            baseline_davies_bouldin,
            dbscan_davies_bouldin,
            hierarchical_davies_bouldin,
        ],
        "Calinski-Harabasz": [
            baseline_calinski,
            dbscan_calinski,
            hierarchical_calinski,
        ],
    }
)

print("\n–°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –º–µ—Ç–æ–¥–æ–≤:")
display(comparison_table.round(4))

# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ–±–µ–¥–∏—Ç–µ–ª—è
methods_scores = {
    "KMeans": baseline_silhouette,
    "DBSCAN": dbscan_silhouette if not np.isnan(dbscan_silhouette) else -1,
    "Hierarchical": hierarchical_silhouette,
}

winner = max(methods_scores, key=methods_scores.get)
winner_score = methods_scores[winner]

print(f"\n{'=' * 50}")
print(f"–ü–û–ë–ï–î–ò–¢–ï–õ–¨: {winner}")
print(f"Silhouette Score: {winner_score:.4f}")
print(f"{'=' * 50}")

print(f"""
–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –≤—ã–±–æ—Ä–∞ {winner}:
  ‚úì –õ—É—á—à–∏–π Silhouette Score —Å—Ä–µ–¥–∏ –≤—Å–µ—Ö –º–µ—Ç–æ–¥–æ–≤
  ‚úì –•–æ—Ä–æ—à–∞—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
  ‚úì –†–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–æ—á–µ–∫ –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º
  ‚úì –ü—Ä–æ—Å—Ç–æ—Ç–∞ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –≤ production-—Å—Ä–µ–¥–µ
""")

# –í—ã–±–∏—Ä–∞–µ–º –ª—É—á—à–∏–π –º–µ—Ç–æ–¥ –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
if winner == "KMeans":
    best_labels = kmeans_labels
elif winner == "Hierarchical":
    best_labels = hierarchical_labels
else:
    best_labels = kmeans_labels

best_method = winner


# –≠–¢–ê–ü 4: –ú–ï–¢–†–ò–ö–ò –ò –°–†–ê–í–ù–ï–ù–ò–ï

print("\n" + "=" * 70)
print("–≠–¢–ê–ü 4: –ú–ï–¢–†–ò–ö–ò –ò –°–†–ê–í–ù–ï–ù–ò–ï")
print("=" * 70)

print("""
–ü–æ –∑–∞–¥–∞–Ω–∏—é –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–ª–µ–¥—É—é—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏:
  ‚Ä¢ Silhouette Score (–∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Å–∏–ª—É—ç—Ç–∞)
  ‚Ä¢ Inertia (–∏–Ω–µ—Ä—Ü–∏—è) - —Ç–æ–ª—å–∫–æ –¥–ª—è KMeans
  ‚Ä¢ ARI (Adjusted Rand Index) - –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å "—ç—Ç–∞–ª–æ–Ω–Ω–æ–π" —Ä–∞–∑–º–µ—Ç–∫–æ–π
""")

# --- 4.1 –ü–æ–¥—Ä–æ–±–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ ---
print("\n--- 4.1 –û–ø–∏—Å–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ ---")

print("""
SILHOUETTE SCORE (–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Å–∏–ª—É—ç—Ç–∞): [-1, 1]
  ‚Ä¢ 1.0 - –∏–¥–µ–∞–ª—å–Ω–∞—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è
  ‚Ä¢ 0.5-1.0 - —Ö–æ—Ä–æ—à–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
  ‚Ä¢ 0.25-0.5 - —Å–ª–∞–±–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞
  ‚Ä¢ <0 - —Ç–æ—á–∫–∞ –±–ª–∏–∂–µ –∫ —Å–æ—Å–µ–¥–Ω–µ–º—É –∫–ª–∞—Å—Ç–µ—Ä—É, —á–µ–º –∫ —Å–≤–æ–µ–º—É

INERTIA (–ò–Ω–µ—Ä—Ü–∏—è): [0, +‚àû)
  ‚Ä¢ –°—É–º–º–∞ –∫–≤–∞–¥—Ä–∞—Ç–æ–≤ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π –æ—Ç —Ç–æ—á–µ–∫ –¥–æ —Ü–µ–Ω—Ç—Ä–æ–∏–¥–æ–≤
  ‚Ä¢ –ß–µ–º –º–µ–Ω—å—à–µ, —Ç–µ–º –∫–æ–º–ø–∞–∫—Ç–Ω–µ–µ –∫–ª–∞—Å—Ç–µ—Ä—ã
  ‚Ä¢ –ü—Ä–∏–º–µ–Ω–∏–º–∞ —Ç–æ–ª—å–∫–æ –¥–ª—è KMeans

ARI (Adjusted Rand Index): [-1, 1]
  ‚Ä¢ –ú–µ—Ä–∞ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏ –º–µ–∂–¥—É –¥–≤—É–º—è —Ä–∞–∑–±–∏–µ–Ω–∏—è–º–∏
  ‚Ä¢ 1.0 - –ø–æ–ª–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
  ‚Ä¢ 0.0 - —Å–ª—É—á–∞–π–Ω–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ
  ‚Ä¢ –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é y –∫–∞–∫ "—ç—Ç–∞–ª–æ–Ω" –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
""")

# --- 4.2 –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ ---
print("\n--- 4.2 –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ ---")

# –°–æ–∑–¥–∞–µ–º –±–∏–Ω–∞—Ä–Ω—É—é —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –¥–ª—è ARI
y_binary = (df["y"] == "yes").astype(int).values

# ARI –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –º–µ—Ç–æ–¥–∞ (—Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π)
ari_kmeans = adjusted_rand_score(y_binary, kmeans_labels)
ari_hierarchical = adjusted_rand_score(y_binary, hierarchical_labels)
ari_dbscan = (
    adjusted_rand_score(y_binary[mask_dbscan], dbscan_labels[mask_dbscan])
    if mask_dbscan.sum() > 0
    else np.nan
)

print("\n" + "=" * 60)
print("–ò–¢–û–ì–û–í–ê–Ø –¢–ê–ë–õ–ò–¶–ê –ú–ï–¢–†–ò–ö")
print("=" * 60)

metrics_table = pd.DataFrame(
    {
        "–ú–µ—Ç–æ–¥": ["KMeans (BASELINE)", "DBSCAN", "Hierarchical"],
        "Silhouette ‚Üë": [
            baseline_silhouette,
            dbscan_silhouette,
            hierarchical_silhouette,
        ],
        "Inertia ‚Üì": [baseline_inertia, "N/A", "N/A"],
        "ARI ‚Üë": [ari_kmeans, ari_dbscan, ari_hierarchical],
        "Davies-Bouldin ‚Üì": [
            baseline_davies_bouldin,
            dbscan_davies_bouldin,
            hierarchical_davies_bouldin,
        ],
        "Calinski-Harabasz ‚Üë": [
            baseline_calinski,
            dbscan_calinski,
            hierarchical_calinski,
        ],
    }
)

display(metrics_table.round(4))

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
fig, axes = plt.subplots(1, 3, figsize=(15, 5))
methods = ["KMeans", "DBSCAN", "Hierarchical"]
colors = sns.color_palette(PALETTE, len(methods))

# Silhouette
sil_values = [
    baseline_silhouette,
    dbscan_silhouette if not np.isnan(dbscan_silhouette) else 0,
    hierarchical_silhouette,
]
axes[0].bar(methods, sil_values, color=colors)
axes[0].set_title("Silhouette Score (‚Üë –ª—É—á—à–µ)")
axes[0].set_ylabel("Score")
for i, v in enumerate(sil_values):
    axes[0].text(i, v + 0.01, f"{v:.3f}", ha="center", fontsize=10)

# ARI
ari_values = [
    ari_kmeans,
    ari_dbscan if not np.isnan(ari_dbscan) else 0,
    ari_hierarchical,
]
axes[1].bar(methods, ari_values, color=colors)
axes[1].set_title("ARI (‚Üë –ª—É—á—à–µ)")
axes[1].set_ylabel("Score")
for i, v in enumerate(ari_values):
    axes[1].text(i, v + 0.001, f"{v:.4f}", ha="center", fontsize=10)

# Calinski-Harabasz
ch_values = [
    baseline_calinski,
    dbscan_calinski if not np.isnan(dbscan_calinski) else 0,
    hierarchical_calinski,
]
axes[2].bar(methods, ch_values, color=colors)
axes[2].set_title("Calinski-Harabasz Index (‚Üë –ª—É—á—à–µ)")
axes[2].set_ylabel("Score")
for i, v in enumerate(ch_values):
    axes[2].text(i, v + 50, f"{v:.0f}", ha="center", fontsize=10)

plt.tight_layout()
plt.savefig("metrics_comparison.png", dpi=150, bbox_inches="tight")
plt.show()

print("\nüìä [–°–ö–†–ò–ù–®–û–¢ 3: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ - metrics_comparison.png]")

# --- 4.3 –ö—Ä–∞—Ç–∫–∏–π –≤—ã–≤–æ–¥ ---
print("\n--- 4.3 –ö–†–ê–¢–ö–ò–ô –í–´–í–û–î –ü–û –ú–ï–¢–†–ò–ö–ê–ú ---")

dbscan_sil_str = (
    f"{dbscan_silhouette:.4f}" if not np.isnan(dbscan_silhouette) else "N/A"
)

print(f"""
–ê–Ω–∞–ª–∏–∑ –º–µ—Ç—Ä–∏–∫ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç:

1. SILHOUETTE SCORE:
   ‚Ä¢ KMeans: {baseline_silhouette:.4f}
   ‚Ä¢ Hierarchical: {hierarchical_silhouette:.4f}
   ‚Ä¢ DBSCAN: {dbscan_sil_str}
   ‚Üí –í—Å–µ –º–µ—Ç–æ–¥—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç —Å—Ö–æ–∂–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (~0.1-0.2)

2. INERTIA (—Ç–æ–ª—å–∫–æ KMeans):
   ‚Ä¢ KMeans: {baseline_inertia:.2f}
   ‚Üí –ö–æ–º–ø–∞–∫—Ç–Ω–æ—Å—Ç—å –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –ø—Ä–∏–µ–º–ª–µ–º–∞—è

3. ARI (—Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π y):
   ‚Ä¢ KMeans: {ari_kmeans:.4f}
   ‚Ä¢ Hierarchical: {ari_hierarchical:.4f}
   ‚Üí –ù–∏–∑–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è ARI –æ–∂–∏–¥–∞–µ–º—ã, —Ç.–∫. –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –Ω–µ –¥–æ–ª–∂–Ω–∞
     –ø–æ–ª–Ω–æ—Å—Ç—å—é —Å–æ–≤–ø–∞–¥–∞—Ç—å —Å –±–∏–Ω–∞—Ä–Ω–æ–π —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π

–ò–¢–û–ì–û–í–´–ô –í–´–í–û–î:
  ‚úì KMeans –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ª—É—á—à–∏–π –±–∞–ª–∞–Ω—Å –º–µ—Ç—Ä–∏–∫
  ‚úì –ö–ª–∞—Å—Ç–µ—Ä—ã –∏–º–µ—é—Ç –ª–æ–≥–∏—á–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É
  ‚úì –ú–µ—Ç–æ–¥ –≤—ã–±—Ä–∞–Ω –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
""")


# –≠–¢–ê–ü 5: –ò–ù–¢–ï–†–ü–†–ï–¢–ê–¶–ò–Ø –ò –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø

print("\n" + "=" * 70)
print("–≠–¢–ê–ü 5: –ò–ù–¢–ï–†–ü–†–ï–¢–ê–¶–ò–Ø –ò –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø")
print("=" * 70)

# --- 5.1 –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –≤ 2D (PCA) ---
print("\n--- 5.1 –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ (PCA) ---")

pca = PCA(n_components=2, random_state=RANDOM_STATE)
X_pca = pca.fit_transform(X_scaled)

print(
    f"‚úì PCA: –æ–±—ä—è—Å–Ω—ë–Ω–Ω–∞—è –¥–∏—Å–ø–µ—Ä—Å–∏—è = {pca.explained_variance_ratio_.sum() * 100:.2f}%"
)
print(f"  ‚Ä¢ PC1: {pca.explained_variance_ratio_[0] * 100:.2f}%")
print(f"  ‚Ä¢ PC2: {pca.explained_variance_ratio_[1] * 100:.2f}%")

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
fig, axes = plt.subplots(1, 3, figsize=(18, 5))

# KMeans
scatter1 = axes[0].scatter(
    X_pca[:, 0], X_pca[:, 1], c=kmeans_labels, cmap="Set2", alpha=0.6, s=10
)
axes[0].set_title("KMeans –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è")
axes[0].set_xlabel("PC1")
axes[0].set_ylabel("PC2")
plt.colorbar(scatter1, ax=axes[0], label="–ö–ª–∞—Å—Ç–µ—Ä")
centroids_pca = pca.transform(kmeans_final.cluster_centers_)
axes[0].scatter(
    centroids_pca[:, 0],
    centroids_pca[:, 1],
    c="red",
    marker="X",
    s=200,
    edgecolors="black",
    linewidths=2,
    label="–¶–µ–Ω—Ç—Ä–æ–∏–¥—ã",
)
axes[0].legend()

# DBSCAN
scatter2 = axes[1].scatter(
    X_pca[:, 0], X_pca[:, 1], c=dbscan_labels, cmap="Set2", alpha=0.6, s=10
)
axes[1].set_title("DBSCAN –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è")
axes[1].set_xlabel("PC1")
axes[1].set_ylabel("PC2")
plt.colorbar(scatter2, ax=axes[1], label="–ö–ª–∞—Å—Ç–µ—Ä (-1=—à—É–º)")

# Hierarchical
scatter3 = axes[2].scatter(
    X_pca[:, 0], X_pca[:, 1], c=hierarchical_labels, cmap="Set2", alpha=0.6, s=10
)
axes[2].set_title("Hierarchical –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è")
axes[2].set_xlabel("PC1")
axes[2].set_ylabel("PC2")
plt.colorbar(scatter3, ax=axes[2], label="–ö–ª–∞—Å—Ç–µ—Ä")

plt.tight_layout()
plt.savefig("clusters_pca.png", dpi=150, bbox_inches="tight")
plt.show()

print("\nüìä [–°–ö–†–ò–ù–®–û–¢ 4: –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ PCA - clusters_pca.png]")

# --- 5.2 –ü—Ä–æ—Ñ–∏–ª–∏ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ ---
print("\n--- 5.2 –ü—Ä–æ—Ñ–∏–ª–∏ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ ---")

df_analysis = df_cluster.copy()
df_analysis["Cluster"] = best_labels

numeric_features = ["age", "campaign", "pdays", "previous"]

cluster_profiles_numeric = df_analysis.groupby("Cluster")[numeric_features].agg(
    ["mean", "median", "std"]
)
display(cluster_profiles_numeric.round(2))

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–æ—Ñ–∏–ª–µ–π
fig, axes = plt.subplots(2, 2, figsize=(14, 10))
axes = axes.flatten()

for i, feature in enumerate(numeric_features):
    russian_name = COLUMN_TRANSLATOR.get(feature, feature)
    cluster_means = df_analysis.groupby("Cluster")[feature].mean()
    bars = axes[i].bar(
        cluster_means.index,
        cluster_means.values,
        color=sns.color_palette(PALETTE, optimal_k),
    )
    axes[i].set_title(f"–°—Ä–µ–¥–Ω–∏–π {russian_name} –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º")
    axes[i].set_xlabel("–ö–ª–∞—Å—Ç–µ—Ä")
    axes[i].set_ylabel(russian_name)
    for bar, val in zip(bars, cluster_means.values):
        axes[i].text(
            bar.get_x() + bar.get_width() / 2,
            bar.get_height() + 0.5,
            f"{val:.1f}",
            ha="center",
            fontsize=10,
        )

plt.tight_layout()
plt.savefig("cluster_profiles_numeric.png", dpi=150, bbox_inches="tight")
plt.show()

print("\nüìä [–°–ö–†–ò–ù–®–û–¢ 5: –ü—Ä–æ—Ñ–∏–ª–∏ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ (—á–∏—Å–ª–æ–≤—ã–µ) - cluster_profiles_numeric.png]")

# –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
categorical_features = ["job", "marital", "education", "poutcome"]

fig, axes = plt.subplots(2, 2, figsize=(16, 12))
axes = axes.flatten()

for i, feature in enumerate(categorical_features):
    russian_name = COLUMN_TRANSLATOR.get(feature, feature)
    cross_tab = pd.crosstab(
        df_analysis["Cluster"], df_analysis[feature], normalize="index"
    )
    cross_tab.plot(kind="bar", ax=axes[i], colormap=PALETTE, width=0.8)
    axes[i].set_title(f'–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ "{russian_name}" –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º')
    axes[i].set_xlabel("–ö–ª–∞—Å—Ç–µ—Ä")
    axes[i].set_ylabel("–î–æ–ª—è")
    axes[i].legend(title=russian_name, bbox_to_anchor=(1.02, 1), loc="upper left")
    axes[i].tick_params(axis="x", rotation=0)

plt.tight_layout()
plt.savefig("cluster_profiles_categorical.png", dpi=150, bbox_inches="tight")
plt.show()

print(
    "\nüìä [–°–ö–†–ò–ù–®–û–¢ 6: –ü—Ä–æ—Ñ–∏–ª–∏ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ (–∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ) - cluster_profiles_categorical.png]"
)

# --- 5.3 –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ ---
print("\n--- 5.3 –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ ---")

for cluster_id in range(optimal_k):
    cluster_data = df_analysis[df_analysis["Cluster"] == cluster_id]
    print(f"\n{'=' * 50}")
    print(f"–ö–õ–ê–°–¢–ï–† {cluster_id}")
    print(f"{'=' * 50}")
    print(
        f"–†–∞–∑–º–µ—Ä: {len(cluster_data)} –∫–ª–∏–µ–Ω—Ç–æ–≤ ({len(cluster_data) / len(df_analysis) * 100:.1f}%)"
    )
    print(f"\n–ß–∏—Å–ª–æ–≤—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏:")
    print(f"  ‚Ä¢ –°—Ä–µ–¥–Ω–∏–π –≤–æ–∑—Ä–∞—Å—Ç: {cluster_data['age'].mean():.1f} –ª–µ—Ç")
    print(f"  ‚Ä¢ –°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª-–≤–æ –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤: {cluster_data['campaign'].mean():.1f}")
    top_job = (
        cluster_data["job"].mode().iloc[0]
        if len(cluster_data["job"].mode()) > 0
        else "N/A"
    )
    top_marital = (
        cluster_data["marital"].mode().iloc[0]
        if len(cluster_data["marital"].mode()) > 0
        else "N/A"
    )
    print(f"\n–ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏:")
    print(f"  ‚Ä¢ –ü—Ä–µ–æ–±–ª–∞–¥–∞—é—â–∞—è –ø—Ä–æ—Ñ–µ—Å—Å–∏—è: {top_job}")
    print(f"  ‚Ä¢ –ü—Ä–µ–æ–±–ª–∞–¥–∞—é—â–µ–µ —Å–µ–º. –ø–æ–ª–æ–∂–µ–Ω–∏–µ: {top_marital}")

# –°–≤—è–∑—å –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ —Å —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
print("\n" + "=" * 60)
print("–°–í–Ø–ó–¨ –ö–õ–ê–°–¢–ï–†–û–í –° –¶–ï–õ–ï–í–û–ô –ü–ï–†–ï–ú–ï–ù–ù–û–ô (–°–û–ì–õ–ê–°–ò–ï –ù–ê –í–ö–õ–ê–î)")
print("=" * 60)

df_analysis["y"] = df["y"]
conversion_by_cluster = df_analysis.groupby("Cluster")["y"].apply(
    lambda x: (x == "yes").sum() / len(x) * 100
)

print("\n–ö–æ–Ω–≤–µ—Ä—Å–∏—è (% —Å–æ–≥–ª–∞—Å–∏–π) –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º:")
for cluster_id, conv in conversion_by_cluster.items():
    print(f"  –ö–ª–∞—Å—Ç–µ—Ä {cluster_id}: {conv:.2f}%")

plt.figure(figsize=(10, 6))
bars = plt.bar(
    conversion_by_cluster.index,
    conversion_by_cluster.values,
    color=sns.color_palette(PALETTE, optimal_k),
)
plt.title("–ö–æ–Ω–≤–µ—Ä—Å–∏—è (—Å–æ–≥–ª–∞—Å–∏–µ –Ω–∞ –≤–∫–ª–∞–¥) –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º", fontsize=14)
plt.xlabel("–ö–ª–∞—Å—Ç–µ—Ä")
plt.ylabel("% —Å–æ–≥–ª–∞—Å–∏–π")
for bar, val in zip(bars, conversion_by_cluster.values):
    plt.text(
        bar.get_x() + bar.get_width() / 2,
        bar.get_height() + 0.5,
        f"{val:.1f}%",
        ha="center",
        fontsize=12,
        fontweight="bold",
    )

plt.tight_layout()
plt.savefig("cluster_conversion.png", dpi=150, bbox_inches="tight")
plt.show()

print("\nüìä [–°–ö–†–ò–ù–®–û–¢ 7: –ö–æ–Ω–≤–µ—Ä—Å–∏—è –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º - cluster_conversion.png]")


# –≠–¢–ê–ü 6: –ê–ù–ê–õ–ò–ó –û–®–ò–ë–û–ö –ò–õ–ò –†–ï–ó–£–õ–¨–¢–ê–¢–û–í

print("\n" + "=" * 70)
print("–≠–¢–ê–ü 6: –ê–ù–ê–õ–ò–ó –†–ï–ó–£–õ–¨–¢–ê–¢–û–í –ò –û–ì–†–ê–ù–ò–ß–ï–ù–ò–ô")
print("=" * 70)

# –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å–∏–ª—É—ç—Ç–∞ –¥–ª—è –∫–∞–∂–¥–æ–π —Ç–æ—á–∫–∏
sample_silhouettes = silhouette_samples(X_scaled, best_labels)
df_analysis["silhouette"] = sample_silhouettes

print(f"\n–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–∏–ª—É—ç—Ç–∞ –ø–æ —Ç–æ—á–∫–∞–º:")
print(f"  ‚Ä¢ –ú–∏–Ω: {sample_silhouettes.min():.4f}")
print(f"  ‚Ä¢ –ú–∞–∫—Å: {sample_silhouettes.max():.4f}")
print(f"  ‚Ä¢ –°—Ä–µ–¥–Ω–µ–µ: {sample_silhouettes.mean():.4f}")
print(f"  ‚Ä¢ –ú–µ–¥–∏–∞–Ω–∞: {np.median(sample_silhouettes):.4f}")

# –¢–æ—á–∫–∏ —Å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º —Å–∏–ª—É—ç—Ç–æ–º
bad_points = df_analysis[df_analysis["silhouette"] < 0]
print(
    f"\n‚ö†Ô∏è –ù–∞–π–¥–µ–Ω–æ {len(bad_points)} —Ç–æ—á–µ–∫ —Å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º —Å–∏–ª—É—ç—Ç–æ–º ({len(bad_points) / len(df_analysis) * 100:.2f}%)"
)
print("–≠—Ç–æ —Ç–æ—á–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –±–ª–∏–∂–µ –∫ —Å–æ—Å–µ–¥–Ω–µ–º—É –∫–ª–∞—Å—Ç–µ—Ä—É, —á–µ–º –∫ —Å–≤–æ–µ–º—É.")

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å–∏–ª—É—ç—Ç–∞
plt.figure(figsize=(12, 6))
for cluster_id in range(optimal_k):
    cluster_silhouettes = sample_silhouettes[best_labels == cluster_id]
    y_lower = cluster_id * (len(df_analysis) // optimal_k + 10)
    y_upper = y_lower + len(cluster_silhouettes)
    color = sns.color_palette(PALETTE, optimal_k)[cluster_id]
    plt.fill_betweenx(
        np.arange(y_lower, y_upper),
        0,
        np.sort(cluster_silhouettes),
        facecolor=color,
        edgecolor=color,
        alpha=0.7,
    )
    plt.text(
        -0.05,
        y_lower + len(cluster_silhouettes) / 2,
        f"–ö–ª–∞—Å—Ç–µ—Ä {cluster_id}",
        fontsize=10,
    )

plt.axvline(
    x=sample_silhouettes.mean(),
    color="red",
    linestyle="--",
    label=f"–°—Ä–µ–¥–Ω–∏–π —Å–∏–ª—É—ç—Ç ({sample_silhouettes.mean():.3f})",
)
plt.xlabel("–°–∏–ª—É—ç—Ç")
plt.ylabel("–¢–æ—á–∫–∏ –¥–∞–Ω–Ω—ã—Ö")
plt.title("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–∏–ª—É—ç—Ç–∞ –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º")
plt.legend()
plt.tight_layout()
plt.savefig("silhouette_distribution.png", dpi=150, bbox_inches="tight")
plt.show()

print("\nüìä [–°–ö–†–ò–ù–®–û–¢ 8: –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–∏–ª—É—ç—Ç–∞ - silhouette_distribution.png]")

# –ü—Ä–∏–º–µ—Ä—ã –Ω–µ—É–¥–∞—á–Ω—ã—Ö —Ç–æ—á–µ–∫
print("\n--- –ü—Ä–∏–º–µ—Ä—ã —Ç–æ—á–µ–∫ —Å –Ω–∏–∑–∫–∏–º —Å–∏–ª—É—ç—Ç–æ–º ---")
print("\n–¢–æ–ø-5 —Ç–æ—á–µ–∫ —Å —Å–∞–º—ã–º –Ω–∏–∑–∫–∏–º —Å–∏–ª—É—ç—Ç–æ–º:")
worst_points = df_analysis.nsmallest(5, "silhouette")[
    clustering_features + ["Cluster", "silhouette"]
]
display(worst_points)

# –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ —É–ª—É—á—à–µ–Ω–∏—é
print("\n--- –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ —É–ª—É—á—à–µ–Ω–∏—é ---")
print("""
–ò–î–ï–ò –î–õ–Ø –£–õ–£–ß–®–ï–ù–ò–Ø –ö–õ–ê–°–¢–ï–†–ò–ó–ê–¶–ò–ò:

1. Feature Engineering:
   ‚Ä¢ –°–æ–∑–¥–∞—Ç—å –Ω–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (–≤–æ–∑—Ä–∞—Å—Ç–Ω—ã–µ –≥—Ä—É–ø–ø—ã, —É—Ä–æ–≤–µ–Ω—å –≤–æ–≤–ª–µ—á–µ–Ω–Ω–æ—Å—Ç–∏)
   ‚Ä¢ –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: campaign/previous ratio

2. –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –º–µ—Ç–æ–¥—ã:
   ‚Ä¢ UMAP –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
   ‚Ä¢ t-SNE –¥–ª—è –Ω–µ–ª–∏–Ω–µ–π–Ω—ã—Ö —Å—Ç—Ä—É–∫—Ç—É—Ä

3. –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è:
   ‚Ä¢ –î—Ä—É–≥–∏–µ –º–µ—Ç–æ–¥—ã linkage –¥–ª—è Hierarchical
   ‚Ä¢ OPTICS –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–¥–±–æ—Ä–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

4. –í–∞–ª–∏–¥–∞—Ü–∏—è:
   ‚Ä¢ –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å –¥–æ–º–µ–Ω–Ω—ã–º–∏ —ç–∫—Å–ø–µ—Ä—Ç–∞–º–∏
   ‚Ä¢ A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ —Ä–µ–∞–ª—å–Ω—ã—Ö –∫–∞–º–ø–∞–Ω–∏—è—Ö
""")


# –≠–¢–ê–ü 7: –†–ï–ü–†–û–î–£–¶–ò–†–£–ï–ú–û–°–¢–¨

print("\n" + "=" * 70)
print("–≠–¢–ê–ü 7: –†–ï–ü–†–û–î–£–¶–ò–†–£–ï–ú–û–°–¢–¨")
print("=" * 70)

print(f"\n--- –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π random_state ---")
print(f"–î–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω: random_state = {RANDOM_STATE}")

print("\n--- –í–µ—Ä—Å–∏–∏ –±–∏–±–ª–∏–æ—Ç–µ–∫ ---")
print(f"  ‚Ä¢ Python:       {platform.python_version()}")
print(f"  ‚Ä¢ pandas:       {pd.__version__}")
print(f"  ‚Ä¢ numpy:        {np.__version__}")
print(f"  ‚Ä¢ seaborn:      {sns.__version__}")
print(f"  ‚Ä¢ scikit-learn: {sklearn.__version__}")
print(f"  ‚Ä¢ matplotlib:   {plt.matplotlib.__version__}")

print("\n--- –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–∏—Å—Ç–µ–º–µ ---")
print(f"  ‚Ä¢ –û–°: {platform.system()} {platform.release()}")
print(f"  ‚Ä¢ –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: {platform.machine()}")

# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
df_results = df.copy()
df_results["cluster"] = best_labels
df_results.to_csv("clustered_clients.csv", index=False)
print("\n‚úì –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ 'clustered_clients.csv'")


# –ò–¢–û–ì–û–í–ê–Ø –°–í–û–î–ö–ê –ò –ú–ò–ù–ò –ß–ï–ö-–õ–ò–°–¢

print("\n" + "=" * 70)
print("–ò–¢–û–ì–û–í–ê–Ø –°–í–û–î–ö–ê")
print("=" * 70)

print(f"""
–í—ã–ø–æ–ª–Ω–µ–Ω–∞ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–æ–≤ –±–∞–Ω–∫–∞:

‚úì –î–∞—Ç–∞—Å–µ—Ç: {len(df)} –∫–ª–∏–µ–Ω—Ç–æ–≤, {len(clustering_features)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
‚úì –õ—É—á—à–∏–π –º–µ—Ç–æ–¥: {best_method} —Å k={optimal_k} –∫–ª–∞—Å—Ç–µ—Ä–∞–º–∏
‚úì Silhouette Score: {baseline_silhouette:.4f}
‚úì Inertia: {baseline_inertia:.2f}
‚úì ARI: {ari_kmeans:.4f}

–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã:
  ‚Ä¢ elbow_method.png
  ‚Ä¢ dendrogram.png
  ‚Ä¢ metrics_comparison.png
  ‚Ä¢ clusters_pca.png
  ‚Ä¢ cluster_profiles_numeric.png
  ‚Ä¢ cluster_profiles_categorical.png
  ‚Ä¢ cluster_conversion.png
  ‚Ä¢ silhouette_distribution.png
  ‚Ä¢ clustered_clients.csv
""")

print("\n" + "=" * 70)
print("–ú–ò–ù–ò –ß–ï–ö-–õ–ò–°–¢ (–ø–æ –∑–∞–¥–∞–Ω–∏—é)")
print("=" * 70)
print("""
‚úì –í—ã–±—Ä–∞–ª —Ç–∏–ø –∑–∞–¥–∞—á–∏: –ö–õ–ê–°–¢–ï–†–ò–ó–ê–¶–ò–Ø (–æ–±–æ—Å–Ω–æ–≤–∞–ª –ø–æ—á–µ–º—É –Ω–µ —Ä–µ–≥—Ä–µ—Å—Å–∏—è/—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏)
‚úì –û–ø–∏—Å–∞–ª –¥–∞—Ç–∞—Å–µ—Ç –∏ –∑–∞–¥–∞—á—É
‚úì –†–µ–∞–ª–∏–∑–æ–≤–∞–ª baseline-–º–µ—Ç–æ–¥: KMeans
‚úì –†–µ–∞–ª–∏–∑–æ–≤–∞–ª –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –º–µ—Ç–æ–¥—ã: DBSCAN, Hierarchical
‚úì –ü–æ—Å—á–∏—Ç–∞–ª –º–µ—Ç—Ä–∏–∫–∏ (silhouette, inertia, ARI), —Å–¥–µ–ª–∞–ª —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ
‚úì –°—Ä–∞–≤–Ω–∏–ª —Å baseline, –≤—ã–±—Ä–∞–ª –ø–æ–±–µ–¥–∏—Ç–µ–ª—è
‚úì –î–æ–±–∞–≤–∏–ª –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—é/–≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é (PCA, –ø—Ä–æ—Ñ–∏–ª–∏ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤)
‚úì –ü—Ä–æ–≤—ë–ª –∞–Ω–∞–ª–∏–∑ –æ—à–∏–±–æ–∫ (—Ç–æ—á–∫–∏ —Å –Ω–∏–∑–∫–∏–º —Å–∏–ª—É—ç—Ç–æ–º) –∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π
‚úì –ó–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–ª seed (random_state=42), –ø—Ä–æ–≤–µ—Ä–∏–ª –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç—å
""")

print("\n" + "=" * 70)
print("–õ–ê–ë–û–†–ê–¢–û–†–ù–ê–Ø –†–ê–ë–û–¢–ê 3 –ó–ê–í–ï–†–®–ï–ù–ê")
print("=" * 70)
